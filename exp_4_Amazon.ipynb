{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "863b7238-a730-4652-8fda-adc4e2f689a9",
   "metadata": {},
   "source": [
    "# 1. Standard (not graph) AE + GNN for node classification from AE codings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca02dbe-f5e4-45d8-995f-ce639c42aa0b",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a2a4cf5-61d6-481a-9729-998af8db12c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.datasets import Amazon\n",
    "from torch_geometric.transforms import NormalizeFeatures\n",
    "from torch_geometric.nn import GCNConv\n",
    "from utils import *\n",
    "from metrics import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a71dc08e-e05d-49ad-9a6b-94d310c01de3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.2488965392112732\n",
      "Epoch 10, Loss: 8.843372597766574e-06\n",
      "Epoch 20, Loss: 9.905079423333518e-06\n",
      "Epoch 30, Loss: 9.905079423333518e-06\n",
      "Epoch 40, Loss: 9.905079423333518e-06\n",
      "Epoch 50, Loss: 9.905079423333518e-06\n",
      "Epoch 60, Loss: 9.905079423333518e-06\n",
      "Epoch 70, Loss: 9.905079423333518e-06\n",
      "Epoch 80, Loss: 9.905079423333518e-06\n",
      "Epoch 90, Loss: 9.905079423333518e-06\n",
      "Epoch 100, Loss: 9.905079423333518e-06\n",
      "Epoch 110, Loss: 9.905079423333518e-06\n",
      "Epoch 120, Loss: 9.905079423333518e-06\n",
      "Epoch 130, Loss: 9.905079423333518e-06\n",
      "Epoch 140, Loss: 9.905079423333518e-06\n",
      "Epoch 150, Loss: 9.905079423333518e-06\n",
      "Epoch 160, Loss: 9.905079423333518e-06\n",
      "Epoch 170, Loss: 9.905079423333518e-06\n",
      "Epoch 180, Loss: 9.905079423333518e-06\n",
      "Epoch 190, Loss: 9.905079423333518e-06\n",
      "Epoch 0, Loss: 2.4851369857788086\n",
      "Epoch 10, Loss: 2.0104217529296875\n",
      "Epoch 20, Loss: 1.9433348178863525\n",
      "Epoch 30, Loss: 1.9240330457687378\n",
      "Epoch 40, Loss: 1.9221112728118896\n",
      "Epoch 50, Loss: 1.9187277555465698\n",
      "Epoch 60, Loss: 1.9129724502563477\n",
      "Epoch 70, Loss: 1.9072632789611816\n",
      "Epoch 80, Loss: 1.8987904787063599\n",
      "Epoch 90, Loss: 1.8967310190200806\n",
      "Epoch 100, Loss: 1.8948252201080322\n",
      "Epoch 110, Loss: 1.8844411373138428\n",
      "Epoch 120, Loss: 1.8815056085586548\n",
      "Epoch 130, Loss: 1.876218318939209\n",
      "Epoch 140, Loss: 1.8706318140029907\n",
      "Epoch 150, Loss: 1.860634684562683\n",
      "Epoch 160, Loss: 1.8509281873703003\n",
      "Epoch 170, Loss: 1.8405979871749878\n",
      "Epoch 180, Loss: 1.8346019983291626\n",
      "Epoch 190, Loss: 1.8249878883361816\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "dataset = Amazon(root='.', name='Computers', transform=NormalizeFeatures())\n",
    "data = dataset[0]\n",
    "X = data.x.numpy()\n",
    "\n",
    "\n",
    "# Define the Autoencoder\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, bottleneck_dim):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, bottleneck_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(bottleneck_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, input_dim),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return encoded, decoded\n",
    "\n",
    "# Define the GCN model\n",
    "class GCN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GCNConv(input_dim, hidden_dim)\n",
    "        self.conv2 = GCNConv(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "# Load the Cora dataset\n",
    "dataset = Amazon(root='.', name='Computers', transform=NormalizeFeatures())\n",
    "data = dataset[0]\n",
    "generate_train_test(data)\n",
    "\n",
    "# Autoencoder Settings\n",
    "input_dim = dataset.num_node_features\n",
    "hidden_dim = 128\n",
    "bottleneck_dim = 32\n",
    "autoencoder = Autoencoder(input_dim, hidden_dim, bottleneck_dim)\n",
    "\n",
    "# Training the Autoencoder\n",
    "optimizer_ae = torch.optim.Adam(autoencoder.parameters(), lr=0.01)\n",
    "criterion_ae = nn.MSELoss()\n",
    "\n",
    "for epoch in range(200):\n",
    "    autoencoder.train()\n",
    "    optimizer_ae.zero_grad()\n",
    "    _, reconstructed = autoencoder(data.x)\n",
    "    loss = criterion_ae(reconstructed, data.x)\n",
    "    loss.backward()\n",
    "    optimizer_ae.step()\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        print(f'Epoch {epoch}, Loss: {loss.item()}')\n",
    "\n",
    "# Preparing the compressed features for the GNN\n",
    "autoencoder.eval()\n",
    "with torch.no_grad():  # Ensure no gradients are computed for the operation within this block\n",
    "    compressed_features, _ = autoencoder(data.x)\n",
    "    compressed_features = compressed_features.detach()  # Detach the features from the graph\n",
    "\n",
    "\n",
    "# Training the GNN\n",
    "gcn = GCN(bottleneck_dim, hidden_dim, dataset.num_classes)\n",
    "optimizer_gcn = torch.optim.Adam(gcn.parameters(), lr=0.01)\n",
    "criterion_gcn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in range(200):\n",
    "    gcn.train()\n",
    "    optimizer_gcn.zero_grad()\n",
    "    out = gcn(compressed_features, data.edge_index)\n",
    "    loss = criterion_gcn(out[data.train_mask], data.y[data.train_mask])\n",
    "    loss.backward()\n",
    "    optimizer_gcn.step()\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        print(f'Epoch {epoch}, Loss: {loss.item()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06fd2ee0-112f-48c5-9c85-06e423b8dc3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Switch model to evaluation mode\n",
    "gcn.eval()\n",
    "\n",
    "# No gradient calculation needed for evaluation\n",
    "with torch.no_grad():\n",
    "    # Forward pass with the test data\n",
    "    test_out = gcn(compressed_features, data.edge_index)\n",
    "    # Use the class with the highest probability as the prediction\n",
    "    test_pred = test_out.argmax(dim=1)\n",
    "    # Calculate the number of correct predictions in the test set\n",
    "    correct = (test_pred[data.test_mask] == data.y[data.test_mask]).sum().item()\n",
    "    # Calculate the test accuracy\n",
    "    test_accuracy = correct / data.test_mask.sum().item()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e5d6f0-3b40-4eb5-8314-2bfb0e5e0887",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3119acc6-c530-46f1-99c4-e9ed7fcc396e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.3751363140676118\n"
     ]
    }
   ],
   "source": [
    "print(f'Test Accuracy: {test_accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1478cb8a-70b7-4732-a4e8-4cae7f1f727b",
   "metadata": {},
   "source": [
    "This obviously does not work. Let's try to fix it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db3f380f-45b2-41f7-bc9a-6626fa565909",
   "metadata": {},
   "source": [
    "# 2. Basic Graph AE + GNN for node classification from AE codings\n",
    "super basic 2 GCNConv layers  \n",
    "2-dim output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1636c0db-77c3-41c0-9851-911fc8489371",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244a4552-f435-4dae-ac32-cb7c02358865",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/asemerjak/.local/lib/python3.10/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'train_test_split_edges' is deprecated, use 'transforms.RandomLinkSplit' instead\n",
      "  warnings.warn(out)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from torch_geometric.transforms import NormalizeFeatures\n",
    "from torch_geometric.nn import GCNConv, GAE\n",
    "from torch_geometric.utils import train_test_split_edges\n",
    "\n",
    "class GCNEncoder(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(GCNEncoder, self).__init__()\n",
    "        self.conv1 = GCNConv(in_channels, 2 * out_channels, cached=True)\n",
    "        self.conv2 = GCNConv(2 * out_channels, out_channels, cached=True)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        return self.conv2(x, edge_index)\n",
    "\n",
    "dataset = Amazon(root='.', name='Computers', transform=NormalizeFeatures())\n",
    "data = dataset[0]\n",
    "generate_train_test(data)\n",
    "# data.train_mask = data.val_mask = data.test_mask = data.y = None  # Ensure these are not used by train_test_split_edges\n",
    "data = train_test_split_edges(data)\n",
    "\n",
    "class GNNNodeClassifier(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super(GNNNodeClassifier, self).__init__()\n",
    "        self.conv1 = GCNConv(in_channels, hidden_channels, cached=True)\n",
    "        self.conv2 = GCNConv(hidden_channels, out_channels, cached=True)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "# Parameters\n",
    "out_channels = 2\n",
    "num_features = dataset.num_features\n",
    "num_classes = dataset.num_classes\n",
    "epochs = 100\n",
    "hidden_channels = 16\n",
    "\n",
    "# Model initialization\n",
    "model = GAE(GCNEncoder(num_features, out_channels)).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# Training the GAE model\n",
    "for epoch in range(1, epochs + 1):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    z = model.encode(data.x.to(device), data.train_pos_edge_index.to(device))\n",
    "    loss = model.recon_loss(z, data.train_pos_edge_index)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if epoch % 10 == 0:\n",
    "        print(f'Epoch: {epoch}, Loss: {loss.item()}')\n",
    "\n",
    "# Update data.x with the encoded features for classification\n",
    "data.x = model.encode(data.x.to(device), data.train_pos_edge_index.to(device)).detach()\n",
    "\n",
    "# Initialize the GNN model for node classification\n",
    "gnn_model = GNNNodeClassifier(out_channels, hidden_channels, num_classes).to(device)\n",
    "optimizer_gnn = torch.optim.Adam(gnn_model.parameters(), lr=0.01)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# Reconstruct full edge_index from the split edges for training the GNN\n",
    "full_edge_index = torch.cat([data.train_pos_edge_index, data.val_pos_edge_index, data.test_pos_edge_index], dim=-1).to(device)\n",
    "\n",
    "# Training the GNN model\n",
    "for epoch in range(100):\n",
    "    gnn_model.train()\n",
    "    optimizer_gnn.zero_grad()\n",
    "    out = gnn_model(data.x, full_edge_index)\n",
    "    loss = criterion(out[data.train_mask], data.y[data.train_mask].to(device))\n",
    "    loss.backward()\n",
    "    optimizer_gnn.step()\n",
    "    if epoch % 10 == 0:\n",
    "        print(f'Epoch {epoch}, Loss: {loss.item()}')\n",
    "\n",
    "# Evaluation\n",
    "gnn_model.eval()\n",
    "with torch.no_grad():\n",
    "    out = gnn_model(data.x, full_edge_index)\n",
    "    pred = out.argmax(dim=1)\n",
    "    correct = (pred[data.test_mask] == data.y[data.test_mask].to(device)).sum()\n",
    "    acc = correct.float() / data.test_mask.sum().float()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c7dfec3-80c5-4635-b2ca-73e8761f653b",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48bbd675-f500-4bd2-921b-3a64da70fce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Accuracy: {acc:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1531c8d1-707c-4c8f-9352-b17f8551af9d",
   "metadata": {},
   "source": [
    "# 3. Basic Graph AE + GNN for node classification from AE codings\n",
    "super basic 2 GCNConv layers  \n",
    "16-dim output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77409894-9f01-4eb9-9b23-cd9f3b2df980",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8727ff70-c793-4c03-b8f0-5b120c2cf902",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from torch_geometric.transforms import NormalizeFeatures\n",
    "from torch_geometric.nn import GCNConv, GAE\n",
    "from torch_geometric.utils import train_test_split_edges\n",
    "\n",
    "class GCNEncoder(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(GCNEncoder, self).__init__()\n",
    "        self.conv1 = GCNConv(in_channels, 2 * out_channels, cached=True)\n",
    "        self.conv2 = GCNConv(2 * out_channels, out_channels, cached=True)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        return self.conv2(x, edge_index)\n",
    "\n",
    "dataset = Amazon(root='.', name='Computers', transform=NormalizeFeatures())\n",
    "data = dataset[0]\n",
    "generate_train_test(data)\n",
    "# data.train_mask = data.val_mask = data.test_mask = data.y = None  # Ensure these are not used by train_test_split_edges\n",
    "data = train_test_split_edges(data)\n",
    "\n",
    "class GNNNodeClassifier(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super(GNNNodeClassifier, self).__init__()\n",
    "        self.conv1 = GCNConv(in_channels, hidden_channels, cached=True)\n",
    "        self.conv2 = GCNConv(hidden_channels, out_channels, cached=True)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "# Parameters\n",
    "out_channels = 16\n",
    "num_features = dataset.num_features\n",
    "num_classes = dataset.num_classes\n",
    "epochs = 100\n",
    "hidden_channels = 32\n",
    "\n",
    "# Model initialization\n",
    "model = GAE(GCNEncoder(num_features, out_channels)).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# Training the GAE model\n",
    "for epoch in range(1, epochs + 1):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    z = model.encode(data.x.to(device), data.train_pos_edge_index.to(device))\n",
    "    loss = model.recon_loss(z, data.train_pos_edge_index)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if epoch % 10 == 0:\n",
    "        print(f'Epoch: {epoch}, Loss: {loss.item()}')\n",
    "\n",
    "# Update data.x with the encoded features for classification\n",
    "data.x = model.encode(data.x.to(device), data.train_pos_edge_index.to(device)).detach()\n",
    "\n",
    "# Initialize the GNN model for node classification\n",
    "gnn_model = GNNNodeClassifier(out_channels, hidden_channels, num_classes).to(device)\n",
    "optimizer_gnn = torch.optim.Adam(gnn_model.parameters(), lr=0.01)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# Reconstruct full edge_index from the split edges for training the GNN\n",
    "full_edge_index = torch.cat([data.train_pos_edge_index, data.val_pos_edge_index, data.test_pos_edge_index], dim=-1).to(device)\n",
    "\n",
    "# Training the GNN model\n",
    "for epoch in range(100):\n",
    "    gnn_model.train()\n",
    "    optimizer_gnn.zero_grad()\n",
    "    out = gnn_model(data.x, full_edge_index)\n",
    "    loss = criterion(out[data.train_mask], data.y[data.train_mask].to(device))\n",
    "    loss.backward()\n",
    "    optimizer_gnn.step()\n",
    "    if epoch % 10 == 0:\n",
    "        print(f'Epoch {epoch}, Loss: {loss.item()}')\n",
    "\n",
    "# Evaluation\n",
    "gnn_model.eval()\n",
    "with torch.no_grad():\n",
    "    out = gnn_model(data.x, full_edge_index)\n",
    "    pred = out.argmax(dim=1)\n",
    "    correct = (pred[data.test_mask] == data.y[data.test_mask].to(device)).sum()\n",
    "    acc = correct.float() / data.test_mask.sum().float()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c373a0c3-2386-4be2-9841-542fd15e4c49",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52925ff8-fb9c-4ad5-8de7-0bd9176f233a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Accuracy: {acc:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb6603a9-b28c-471f-901f-b654c24abd20",
   "metadata": {},
   "source": [
    "# 4. Basic Graph AE for DR\n",
    "super basic 2 GCNConv layers  \n",
    "2-dim output straight for visualisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "607bd9e3-1dce-4297-bae4-0c145040ccc8",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ead35c2-cc9b-422e-b5e9-9c7e76ba186a",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_metrics = LocalMetric()\n",
    "local_metrics_tsne = LocalMetric()\n",
    "\n",
    "dataset_name=\"Amazon\"\n",
    "algorithm_name=\"GAE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63aa499-57d3-476e-b2bc-1a55df036e5b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from torch_geometric.transforms import NormalizeFeatures\n",
    "from torch_geometric.nn import GCNConv, GAE\n",
    "from torch_geometric.utils import train_test_split_edges\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class GCNEncoder(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(GCNEncoder, self).__init__()\n",
    "        self.conv1 = GCNConv(in_channels, 2 * out_channels, cached=True)\n",
    "        self.conv2 = GCNConv(2 * out_channels, out_channels, cached=True)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        return self.conv2(x, edge_index)\n",
    "\n",
    "dataset = Amazon(root='.', name='Computers', transform=NormalizeFeatures())\n",
    "data = dataset[0]\n",
    "generate_train_test(data)\n",
    "data = train_test_split_edges(data)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Parameters for visualization\n",
    "out_channels = 2  # Set to 2 for 2D visualization\n",
    "num_features = dataset.num_features\n",
    "\n",
    "model = GAE(GCNEncoder(num_features, out_channels)).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# Training the GAE model to encode node features into 2D\n",
    "for epoch in range(1, 101):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    z = model.encode(data.x.to(device), data.train_pos_edge_index.to(device))\n",
    "    loss = model.recon_loss(z, data.train_pos_edge_index)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if epoch % 10 == 0:\n",
    "        print(f'Epoch: {epoch}, Loss: {loss.item()}')\n",
    "\n",
    "# Encode and detach the features for visualization\n",
    "encoded_features = model.encode(data.x.to(device), data.train_pos_edge_index.to(device)).detach().cpu().numpy()\n",
    "\n",
    "# Visualization of the 2D encoded features\n",
    "labels = data.y.cpu().numpy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79cc9d62-1c9c-4128-86ce-7175a75de4c2",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ddb533-218b-47f0-9e58-d282a36fae06",
   "metadata": {},
   "outputs": [],
   "source": [
    "GAE_variant = \"basic\"\n",
    "\n",
    "local_metrics.calculate_knn_gain_and_dr_quality(\n",
    "    X_lds=encoded_features,\n",
    "    X_hds=X,\n",
    "    labels=labels,\n",
    "    method_name=\"{} {}\".format(f\"{dataset_name}\", f\"{algorithm_name}-{GAE_variant}\"),\n",
    ")\n",
    "\n",
    "visualise(encoded_features, labels, '2D Visualization of Encoded Node Features')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a240332-a7a3-450d-b707-eacb94544022",
   "metadata": {},
   "source": [
    "# 5. Basic Graph AE + tSNE\n",
    "super basic 2 GCNConv layers  \n",
    "16-dim output -> tSNE (2dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d62ec897-e523-4870-9802-a99da4fe34a7",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3efa5e1-b62a-4c5c-8068-79a35e6e88fa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from torch_geometric.transforms import NormalizeFeatures\n",
    "from torch_geometric.nn import GCNConv, GAE\n",
    "from torch_geometric.utils import train_test_split_edges\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Parameters for the encoder\n",
    "out_channels = 16  # Increase the capacity\n",
    "num_features = dataset.num_features\n",
    "\n",
    "# Model initialization\n",
    "model = GAE(GCNEncoder(num_features, out_channels)).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)  # Add weight decay for L2 regularization\n",
    "\n",
    "# Training the GAE model\n",
    "for epoch in range(1, 201):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    z = model.encode(data.x.to(device), data.train_pos_edge_index.to(device))\n",
    "    loss = model.recon_loss(z, data.train_pos_edge_index)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if epoch % 10 == 0:\n",
    "        print(f'Epoch: {epoch}, Loss: {loss.item()}')\n",
    "\n",
    "# Encode to a higher dimension for better representation, then use t-SNE\n",
    "encoded_features = model.encode(data.x.to(device), data.train_pos_edge_index.to(device)).detach().cpu().numpy()\n",
    "\n",
    "# Apply t-SNE to the encoded features\n",
    "tsne = TSNE(n_components=2, perplexity=30, n_iter=300)\n",
    "tsne_results = tsne.fit_transform(encoded_features)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc8e9ae-300e-4f7d-84b1-8a788468f3fa",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46928d96-5f4c-40e6-8d44-0d4c61605060",
   "metadata": {},
   "outputs": [],
   "source": [
    "GAE_variant = \"basic + tSNE\"\n",
    "\n",
    "local_metrics_tsne.calculate_knn_gain_and_dr_quality(\n",
    "    X_lds=tsne_results,\n",
    "    X_hds=X,\n",
    "    labels=labels,\n",
    "    method_name=\"{} {}\".format(f\"{dataset_name}\", f\"{algorithm_name}-{GAE_variant}\"))\n",
    "\n",
    "visualise(tsne_results, labels, '2D Visualization of Node Features with t-SNE')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62aad22a-54fc-48bd-bd9f-732c664ad3b0",
   "metadata": {},
   "source": [
    "# 6. Graph AE with skip connections +tSNE\n",
    "Three GCNConv layers with a skip connection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e962470b-b780-4ce7-b1ab-621689e26e27",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787271d4-12c3-45be-bd65-8ac8c661476b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnhancedGCNEncoder(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(EnhancedGCNEncoder, self).__init__()\n",
    "        self.base_conv1 = GCNConv(in_channels, 2 * out_channels, cached=True)\n",
    "        self.base_conv2 = GCNConv(2 * out_channels, 2 * out_channels, cached=True)\n",
    "        self.skip_conv1 = GCNConv(in_channels, 2 * out_channels, cached=True)  # Skip connection\n",
    "        self.conv3 = GCNConv(2 * out_channels, out_channels, cached=True)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        skip1 = F.relu(self.skip_conv1(x, edge_index))\n",
    "        x = F.relu(self.base_conv1(x, edge_index))\n",
    "        x = F.relu(self.base_conv2(x + skip1, edge_index))  # Combine with skip connection\n",
    "        return self.conv3(x, edge_index)\n",
    "\n",
    "# Parameters for the encoder\n",
    "out_channels = 16  # Increase the capacity\n",
    "num_features = dataset.num_features\n",
    "\n",
    "# Model initialization\n",
    "model = GAE(EnhancedGCNEncoder(num_features, out_channels)).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)  # Add weight decay for L2 regularization\n",
    "\n",
    "# Training the GAE model\n",
    "for epoch in range(1, 201):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    z = model.encode(data.x.to(device), data.train_pos_edge_index.to(device))\n",
    "    loss = model.recon_loss(z, data.train_pos_edge_index)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if epoch % 10 == 0:\n",
    "        print(f'Epoch: {epoch}, Loss: {loss.item()}')\n",
    "\n",
    "# Encode to a higher dimension for better representation, then use t-SNE\n",
    "encoded_features = model.encode(data.x.to(device), data.train_pos_edge_index.to(device)).detach().cpu().numpy()\n",
    "\n",
    "# Apply t-SNE to the encoded features\n",
    "tsne = TSNE(n_components=2, perplexity=30, n_iter=300, metric='cosine')\n",
    "tsne_results = tsne.fit_transform(encoded_features)\n",
    "\n",
    "# Visualization of the 2D t-SNE results\n",
    "labels = data.y.cpu().numpy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1823ac50-4cec-4951-a33a-7b1a6c62d889",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f67207-9a27-4260-9798-a263715c4cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "GAE_variant = \"skip cons + tSNE\"\n",
    "\n",
    "local_metrics_tsne.calculate_knn_gain_and_dr_quality(\n",
    "    X_lds=tsne_results,\n",
    "    X_hds=X,\n",
    "    labels=labels,\n",
    "    method_name=\"{} {}\".format(f\"{dataset_name}\", f\"{algorithm_name}-{GAE_variant}\"))\n",
    "\n",
    "visualise(tsne_results, labels, '2D Visualization of Node Features with t-SNE')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2c0524f-a56c-4ae3-abea-0bd4e796ea57",
   "metadata": {},
   "source": [
    "# 7. Graph AE with skip connections\n",
    "Three GCNConv layers with a skip connection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed3ad3a0-54fc-4adc-bd3c-a534efa15222",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5203ad6-86cf-4e4e-b016-f45576cbf9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Amazon(root='.', name='Computers', transform=NormalizeFeatures())\n",
    "data = dataset[0]\n",
    "data = train_test_split_edges(data)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Parameters for visualization\n",
    "out_channels = 2  # Set to 2 for 2D visualization\n",
    "num_features = dataset.num_features\n",
    "\n",
    "model = GAE(EnhancedGCNEncoder(num_features, out_channels)).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# Training the GAE model to encode node features into 2D\n",
    "for epoch in range(1, 101):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    z = model.encode(data.x.to(device), data.train_pos_edge_index.to(device))\n",
    "    loss = model.recon_loss(z, data.train_pos_edge_index)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if epoch % 10 == 0:\n",
    "        print(f'Epoch: {epoch}, Loss: {loss.item()}')\n",
    "\n",
    "# Encode and detach the features for visualization\n",
    "encoded_features = model.encode(data.x.to(device), data.train_pos_edge_index.to(device)).detach().cpu().numpy()\n",
    "\n",
    "# Visualization of the 2D encoded features\n",
    "labels = data.y.cpu().numpy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d1d2d89-a9da-4a93-b2ec-327665b74e74",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de18a91f-1663-4e64-896d-af101e114efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "GAE_variant = \"skip cons\"\n",
    "\n",
    "local_metrics.calculate_knn_gain_and_dr_quality(\n",
    "    X_lds=encoded_features,\n",
    "    X_hds=X,\n",
    "    labels=labels,\n",
    "    method_name=\"{} {}\".format(f\"{dataset_name}\", f\"{algorithm_name}-{GAE_variant}\"))\n",
    "\n",
    "visualise(encoded_features, labels, '2D Visualization of Encoded Node Features')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af66b5d-d21e-4535-a677-5816f11c74d0",
   "metadata": {},
   "source": [
    "# 8. Graph AE with attention\n",
    "Two GATConv layers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd2a5e9-57e1-4900-8d75-6877b9002603",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b51eaee-4bb2-4fd3-a4ea-f7345d5dd329",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import GATConv\n",
    "\n",
    "class GATEncoder(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(GATEncoder, self).__init__()\n",
    "        self.conv1 = GATConv(in_channels, 2 * out_channels, heads=8, dropout=0.6)\n",
    "        # Concatenate multi-head outputs so the final output will be 2*out_channels*8\n",
    "        self.conv2 = GATConv(2 * out_channels * 8, out_channels, heads=1, concat=False, dropout=0.6)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = F.dropout(x, p=0.6, training=self.training)\n",
    "        x = F.elu(self.conv1(x, edge_index))\n",
    "        x = F.dropout(x, p=0.6, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n",
    "\n",
    "dataset = Amazon(root='.', name='Computers', transform=NormalizeFeatures())\n",
    "data = dataset[0]\n",
    "generate_train_test(data)\n",
    "data = train_test_split_edges(data)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Parameters for visualization\n",
    "out_channels = 2  # Set to 2 for 2D visualization\n",
    "num_features = dataset.num_features\n",
    "\n",
    "model = GAE(GATEncoder(num_features, out_channels)).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# Training the GAE model to encode node features into 2D\n",
    "for epoch in range(1, 201):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    z = model.encode(data.x.to(device), data.train_pos_edge_index.to(device))\n",
    "    loss = model.recon_loss(z, data.train_pos_edge_index)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if epoch % 10 == 0:\n",
    "        print(f'Epoch: {epoch}, Loss: {loss.item()}')\n",
    "\n",
    "# Encode and detach the features for visualization\n",
    "encoded_features = model.encode(data.x.to(device), data.train_pos_edge_index.to(device)).detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbb34ea2-9f8f-4ea7-8b60-8661d8547dbd",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7feb78f0-0e49-41ea-a51a-dccd54d1afa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "GAE_variant = \"attention\"\n",
    "\n",
    "local_metrics.calculate_knn_gain_and_dr_quality(\n",
    "    X_lds=encoded_features,\n",
    "    X_hds=X,\n",
    "    labels=labels,\n",
    "    method_name=\"{} {}\".format(f\"{dataset_name}\", f\"{algorithm_name}-{GAE_variant}\"))\n",
    "\n",
    "visualise(encoded_features, labels, '2D Visualization of Encoded Node Features')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d91d0b1-1fe5-4d6a-a49a-b46c9c5a324e",
   "metadata": {},
   "source": [
    "# 8. Graph AE with attention + tSNE\n",
    "Two GATConv layers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "497ba855-9e53-4483-a89a-4dcedd7f1a71",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be347f5f-36ad-401c-8f4d-0566f2f568e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for the encoder\n",
    "out_channels = 16  # Increase the capacity\n",
    "num_features = dataset.num_features\n",
    "\n",
    "# Model initialization\n",
    "model = GAE(GATEncoder(num_features, out_channels)).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)  # Add weight decay for L2 regularization\n",
    "\n",
    "# Training the GAE model\n",
    "for epoch in range(1, 201):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    z = model.encode(data.x.to(device), data.train_pos_edge_index.to(device))\n",
    "    loss = model.recon_loss(z, data.train_pos_edge_index)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if epoch % 10 == 0:\n",
    "        print(f'Epoch: {epoch}, Loss: {loss.item()}')\n",
    "\n",
    "# Encode to a higher dimension for better representation, then use t-SNE\n",
    "encoded_features = model.encode(data.x.to(device), data.train_pos_edge_index.to(device)).detach().cpu().numpy()\n",
    "\n",
    "# Apply t-SNE to the encoded features\n",
    "tsne = TSNE(n_components=2, perplexity=30, n_iter=300, metric='cosine')\n",
    "tsne_results = tsne.fit_transform(encoded_features)\n",
    "\n",
    "# Visualization of the 2D t-SNE results\n",
    "labels = data.y.cpu().numpy()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a65724f9-569d-4fe3-be1c-16949b554931",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7088a69c-6476-4e06-978c-b1e8e339946d",
   "metadata": {},
   "outputs": [],
   "source": [
    "GAE_variant = \"attention + tSNE\"\n",
    "\n",
    "local_metrics_tsne.calculate_knn_gain_and_dr_quality(\n",
    "    X_lds=tsne_results,\n",
    "    X_hds=X,\n",
    "    labels=labels,\n",
    "    method_name=\"{} {}\".format(f\"{dataset_name}\", f\"{algorithm_name}-{GAE_variant}\"))\n",
    "\n",
    "visualise(tsne_results, labels, '2D Visualization of Node Features with t-SNE')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2457c20b-fc89-4dd0-bf64-d0019ada053e",
   "metadata": {},
   "source": [
    "# 9. Graph AE with skip & residual connections\n",
    "3 GCNConv layers with skip connections."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce44fa7-a8ef-4ecb-8aca-b36afeab1827",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3056da4-fb58-4cbd-b48e-c8c8f09e5408",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ComplexGCNEncoder(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super(ComplexGCNEncoder, self).__init__()\n",
    "        # Encoder with skip connections\n",
    "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
    "        self.conv3 = GCNConv(hidden_channels, out_channels)\n",
    "        self.skip_conv1 = GCNConv(in_channels, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        skip1 = F.relu(self.skip_conv1(x, edge_index))\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = F.relu(self.conv2(x, edge_index)) + x  # Residual connection\n",
    "        x = self.conv3(x, edge_index) + skip1  # Skip connection\n",
    "        return x\n",
    "\n",
    "dataset = Amazon(root='.', name='Computers', transform=NormalizeFeatures())\n",
    "data = dataset[0]\n",
    "generate_train_test(data)\n",
    "data = train_test_split_edges(data)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Parameters for visualization\n",
    "out_channels = 2  # Set to 2 for 2D visualization\n",
    "num_features = dataset.num_features\n",
    "hidden_channels=16\n",
    "\n",
    "model = GAE(ComplexGCNEncoder(num_features, hidden_channels, out_channels)).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# Training the GAE model to encode node features into 2D\n",
    "for epoch in range(1, 201):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    z = model.encode(data.x.to(device), data.train_pos_edge_index.to(device))\n",
    "    loss = model.recon_loss(z, data.train_pos_edge_index)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if epoch % 10 == 0:\n",
    "        print(f'Epoch: {epoch}, Loss: {loss.item()}')\n",
    "\n",
    "# Encode and detach the features for visualization\n",
    "encoded_features = model.encode(data.x.to(device), data.train_pos_edge_index.to(device)).detach().cpu().numpy()\n",
    "\n",
    "# Visualization of the 2D encoded features\n",
    "labels = data.y.cpu().numpy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88566bad-ade5-4229-aa21-c0ae6f3acec4",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96be4fa6-633f-45bc-b252-24e35815c084",
   "metadata": {},
   "outputs": [],
   "source": [
    "GAE_variant = \"skip + residual cons\"\n",
    "\n",
    "local_metrics.calculate_knn_gain_and_dr_quality(\n",
    "    X_lds=encoded_features,\n",
    "    X_hds=X,\n",
    "    labels=labels,\n",
    "    method_name=\"{} {}\".format(f\"{dataset_name}\", f\"{algorithm_name}-{GAE_variant}\"))\n",
    "\n",
    "visualise(encoded_features, labels, '2D Visualization of Encoded Node Features')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d531f436-25ac-4f2e-95d4-6f6ee54f6609",
   "metadata": {},
   "source": [
    "# 10. Graph AE with residual connection\n",
    "Three GCNConv layers with a residual connection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c65da5-b8c5-459d-aa3d-7ed23d6d60bd",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3107a3ce-4663-49bd-a9e7-2e5d385507f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualGCNEncoder(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super(ResidualGCNEncoder, self).__init__()\n",
    "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
    "        self.conv3 = GCNConv(hidden_channels, out_channels)\n",
    "        # Residual connection from input to output\n",
    "        self.shortcut = torch.nn.Linear(in_channels, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        identity = x\n",
    "\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = F.relu(self.conv2(x, edge_index))\n",
    "        \n",
    "        if x.size(-1) != identity.size(-1):\n",
    "            identity = self.shortcut(identity)\n",
    "        \n",
    "        x = self.conv3(x, edge_index)\n",
    "        \n",
    "        x += identity  # Add the input to the output\n",
    "        return x\n",
    "\n",
    "dataset = Amazon(root='.', name='Computers', transform=NormalizeFeatures())\n",
    "data = dataset[0]\n",
    "generate_train_test(data)\n",
    "data = train_test_split_edges(data)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Parameters for visualization\n",
    "out_channels = 2  # Set to 2 for 2D visualization\n",
    "num_features = dataset.num_features\n",
    "hidden_channels=16\n",
    "\n",
    "model = GAE(ResidualGCNEncoder(num_features, hidden_channels, out_channels)).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# Training the GAE model to encode node features into 2D\n",
    "for epoch in range(1, 201):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    z = model.encode(data.x.to(device), data.train_pos_edge_index.to(device))\n",
    "    loss = model.recon_loss(z, data.train_pos_edge_index)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if epoch % 10 == 0:\n",
    "        print(f'Epoch: {epoch}, Loss: {loss.item()}')\n",
    "\n",
    "# Encode and detach the features for visualization\n",
    "encoded_features = model.encode(data.x.to(device), data.train_pos_edge_index.to(device)).detach().cpu().numpy()\n",
    "\n",
    "# Visualization of the 2D encoded features\n",
    "labels = data.y.cpu().numpy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d5daed-1d49-40a9-893f-3785259a3e57",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e377cfa-230f-4fa5-9f50-5e82902d8ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "GAE_variant = \"residual cons\"\n",
    "\n",
    "local_metrics.calculate_knn_gain_and_dr_quality(\n",
    "    X_lds=encoded_features,\n",
    "    X_hds=X,\n",
    "    labels=labels,\n",
    "    method_name=\"{} {}\".format(f\"{dataset_name}\", f\"{algorithm_name}-{GAE_variant}\"))\n",
    "\n",
    "visualise(encoded_features, labels, '2D Visualization of Encoded Node Features')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e77781f-b407-48e3-bac3-5fa1c12800e9",
   "metadata": {},
   "source": [
    "# 11. Graph AE with attention & normalization\n",
    "Two GATConv layers with layer normalization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f68455e-062c-4f3a-b1ef-21f57d85ab06",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72052e0e-e8a7-4899-81db-ade0d9ca3458",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import GATConv, LayerNorm\n",
    "\n",
    "class GATWithLayerNormEncoder(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, heads=3, dropout_rate=0.6):\n",
    "        super(GATWithLayerNormEncoder, self).__init__()\n",
    "        # Define the first layer with multiple heads\n",
    "        self.conv1 = GATConv(in_channels, hidden_channels, heads=heads, dropout=dropout_rate)\n",
    "        # For the second layer, we want to reduce the dimension to our desired output dimension\n",
    "        self.conv2 = GATConv(hidden_channels * heads, out_channels, heads=1, concat=False, dropout=dropout_rate)\n",
    "        # Layer normalization\n",
    "        self.ln1 = LayerNorm(hidden_channels * heads)\n",
    "        self.ln2 = LayerNorm(out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index, dropout_rate=0.6):\n",
    "        x = F.dropout(x, p=dropout_rate, training=self.training)\n",
    "        x = F.elu(self.conv1(x, edge_index))\n",
    "        x = self.ln1(x)\n",
    "        x = F.dropout(x, p=dropout_rate, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = self.ln2(x)\n",
    "        return x\n",
    "\n",
    "dataset = Amazon(root='.', name='Amazon', transform=NormalizeFeatures())\n",
    "data = dataset[0]\n",
    "generate_train_test(data)\n",
    "data = train_test_split_edges(data)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Parameters for visualization\n",
    "out_channels = 2  # Set to 2 for 2D visualization\n",
    "num_features = dataset.num_features\n",
    "hidden_channels=16\n",
    "\n",
    "model = GAE(GATWithLayerNormEncoder(num_features, hidden_channels, out_channels)).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# Training the GAE model to encode node features into 2D\n",
    "for epoch in range(1, 201):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    z = model.encode(data.x.to(device), data.train_pos_edge_index.to(device))\n",
    "    loss = model.recon_loss(z, data.train_pos_edge_index)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if epoch % 10 == 0:\n",
    "        print(f'Epoch: {epoch}, Loss: {loss.item()}')\n",
    "\n",
    "# Encode and detach the features for visualization\n",
    "encoded_features = model.encode(data.x.to(device), data.train_pos_edge_index.to(device)).detach().cpu().numpy()\n",
    "\n",
    "labels = data.y.cpu().numpy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "374bbc0e-ce31-418c-9694-4513f6985a8e",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2afd286-c1bb-4110-aee8-7f37c6a1a66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "GAE_variant = \"attention + normalization\"\n",
    "\n",
    "local_metrics.calculate_knn_gain_and_dr_quality(\n",
    "    X_lds=encoded_features,\n",
    "    X_hds=X,\n",
    "    labels=labels,\n",
    "    method_name=\"{} {}\".format(f\"{dataset_name}\", f\"{algorithm_name}-{GAE_variant}\"))\n",
    "\n",
    "visualise(encoded_features, labels, '2D Visualization of Encoded Node Features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d83f41-c645-485d-9bcb-421b1f474099",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_metrics.visualize(f\"{dataset_name} - {algorithm_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2adedc4b-7bd4-4288-8200-1da2d4ffa171",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_metrics_tsne.visualize(f\"{dataset_name} - {algorithm_name} + tSNE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7bdc40-8f5c-434d-94ef-56842ea0a3d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
