{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4befa5cd-e1e4-4854-8669-6408cd8972b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from sklearn.neighbors import kneighbors_graph\n",
    "import numpy as np\n",
    "from torch_geometric.data import Data\n",
    "from scipy.sparse import coo_matrix\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from torch_geometric.transforms import NormalizeFeatures\n",
    "from torch_geometric.nn import GCNConv, GAE\n",
    "from torch_geometric.utils import train_test_split_edges\n",
    "from utils import *\n",
    "from metrics import *\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "# Load the Fashion-MNIST dataset\n",
    "def load_fmnist():\n",
    "    transform = transforms.Compose([transforms.ToTensor()])\n",
    "    train_dataset = datasets.FashionMNIST(root='.', train=True, transform=transform, download=True)\n",
    "    return train_dataset\n",
    "\n",
    "# Convert images to feature vectors\n",
    "def preprocess_data(dataset):\n",
    "    data = dataset.data.numpy()\n",
    "    num_samples = data.shape[0]\n",
    "    data = data.reshape(num_samples, -1) / 255.0\n",
    "    labels = dataset.targets.numpy()\n",
    "    return data, labels\n",
    "\n",
    "def create_knn_graph_with_random_neighbor(data, k):\n",
    "    knn_graph = kneighbors_graph(data, k, mode='connectivity', include_self=False)\n",
    "    coo = coo_matrix(knn_graph)\n",
    "    row = coo.row.tolist()\n",
    "    col = coo.col.tolist()\n",
    "\n",
    "    # Add one random neighbor for each node\n",
    "    num_samples = data.shape[0]\n",
    "    for i in range(num_samples):\n",
    "        random_neighbor = random.choice(range(num_samples))\n",
    "        row.append(i)\n",
    "        col.append(random_neighbor)\n",
    "\n",
    "    new_knn_graph = coo_matrix((np.ones(len(row)), (row, col)), shape=(num_samples, num_samples))\n",
    "    return new_knn_graph\n",
    "\n",
    "# Convert the sparse matrix to edge_index format for PyTorch Geometric\n",
    "def convert_to_torch_geometric_graph(knn_graph):\n",
    "    coo = coo_matrix(knn_graph)\n",
    "    edge_index = torch.tensor(np.vstack((coo.row, coo.col)), dtype=torch.long)\n",
    "    return edge_index\n",
    "\n",
    "# Main function to execute the steps\n",
    "def get_fmnist_graph(n_samples=35000):\n",
    "    # Load and preprocess the data\n",
    "    train_dataset = load_fmnist()\n",
    "    x_train, y_train = preprocess_data(train_dataset)\n",
    "    \n",
    "    # Use a subset of the data for simplicity (e.g., first 1000 samples)\n",
    "    x_subset = x_train[:n_samples]\n",
    "    y_subset = y_train[:n_samples]\n",
    "    \n",
    "    # Create KNN graph\n",
    "    k = 4  # Number of neighbors\n",
    "    knn_graph = create_knn_graph_with_random_neighbor(x_subset, k)\n",
    "    \n",
    "    # Convert to PyTorch Geometric Data object\n",
    "    edge_index = convert_to_torch_geometric_graph(knn_graph)\n",
    "    x = torch.tensor(x_subset, dtype=torch.float)\n",
    "    y = torch.tensor(y_subset, dtype=torch.long)\n",
    "    data = Data(x=x, edge_index=edge_index, y=y)\n",
    "    \n",
    "    # Set additional attributes for compatibility\n",
    "    data.num_node_features = data.x.shape[1]\n",
    "    data.num_classes = len(torch.unique(data.y))\n",
    "    data.num_features = data.num_node_features\n",
    "    \n",
    "    # Print the Data object to verify\n",
    "    print(data)\n",
    "    print(f\"Number of node features: {data.num_node_features}\")\n",
    "    print(f\"Number of classes: {data.num_classes}\")\n",
    "    print(f\"Number of features: {data.num_features}\")\n",
    "\n",
    "    generate_train_test(data)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61ebc338-2bb5-4ad0-ac04-527f7b26c1c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[25000, 784], edge_index=[2, 125000], y=[25000], num_node_features=784, num_classes=10, num_features=784)\n",
      "Number of node features: 784\n",
      "Number of classes: 10\n",
      "Number of features: 784\n"
     ]
    }
   ],
   "source": [
    "data = get_fmnist_graph(25000)\n",
    "\n",
    "X = data.x.numpy()\n",
    "\n",
    "local_metrics = LocalMetric()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec30338-22cb-4ee9-9430-eeea63e5bd9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/asemerjak/.local/lib/python3.10/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'train_test_split_edges' is deprecated, use 'transforms.RandomLinkSplit' instead\n",
      "  warnings.warn(out)\n"
     ]
    }
   ],
   "source": [
    "# dataset = Planetoid(root='.', name='Cora', transform=NormalizeFeatures())\n",
    "# data = dataset[0]\n",
    "# data.train_mask = data.val_mask = data.test_mask = data.y = None  # Ensure these are not used by train_test_split_edges\n",
    "data = train_test_split_edges(data)\n",
    "\n",
    "class ResidualGCNEncoder(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super(ResidualGCNEncoder, self).__init__()\n",
    "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
    "        self.conv3 = GCNConv(hidden_channels, out_channels)\n",
    "        # Residual connection from input to output\n",
    "        self.shortcut = torch.nn.Linear(in_channels, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        identity = x\n",
    "\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = F.relu(self.conv2(x, edge_index))\n",
    "\n",
    "        if x.size(-1) != identity.size(-1):\n",
    "            identity = self.shortcut(identity)\n",
    "\n",
    "        x = self.conv3(x, edge_index)\n",
    "\n",
    "        x += identity  # Add the input to the output\n",
    "        return x\n",
    "\n",
    "\n",
    "class GNNNodeClassifier(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super(GNNNodeClassifier, self).__init__()\n",
    "        self.conv1 = GCNConv(in_channels, hidden_channels, cached=True)\n",
    "        self.conv2 = GCNConv(hidden_channels, out_channels, cached=True)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "# Parameters\n",
    "out_channels_AE = 2\n",
    "num_features = data.num_features\n",
    "num_classes = data.num_classes\n",
    "epochs_AE = 200\n",
    "hidden_channels_AE = 16\n",
    "\n",
    "# Model initialization\n",
    "model = GAE(ResidualGCNEncoder(num_features, hidden_channels_AE, out_channels_AE)).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "GAE_loss_history = []\n",
    "\n",
    "# Training the GAE model\n",
    "for epoch in range(1, epochs_AE + 1):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    z = model.encode(data.x.to(device), data.train_pos_edge_index.to(device))\n",
    "    loss = model.recon_loss(z, data.train_pos_edge_index)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    GAE_loss_history.append(loss.item())\n",
    "    if epoch % 10 == 0:\n",
    "        print(f'Epoch: {epoch}, Loss: {loss.item()}')\n",
    "\n",
    "# Update data.x with the encoded features for classification\n",
    "data.x = model.encode(data.x.to(device), data.train_pos_edge_index.to(device)).detach()\n",
    "\n",
    "# Initialize the GNN model for node classification\n",
    "gnn_model = GNNNodeClassifier(out_channels, 64, num_classes).to(device)\n",
    "optimizer_gnn = torch.optim.Adam(gnn_model.parameters(), lr=0.01)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# Reconstruct full edge_index from the split edges for training the GNN\n",
    "full_edge_index = torch.cat([data.train_pos_edge_index, data.val_pos_edge_index, data.test_pos_edge_index], dim=-1).to(device)\n",
    "\n",
    "GNN_loss_history = []\n",
    "\n",
    "# Training the GNN model\n",
    "for epoch in range(300):\n",
    "    gnn_model.train()\n",
    "    optimizer_gnn.zero_grad()\n",
    "    out = gnn_model(data.x, full_edge_index)\n",
    "    loss = criterion(out[data.train_mask], data.y[data.train_mask].to(device))\n",
    "    loss.backward()\n",
    "    optimizer_gnn.step()\n",
    "    GNN_loss_history.append(loss.item())\n",
    "    if epoch % 10 == 0:\n",
    "        print(f'Epoch {epoch}, Loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38973aa-6b33-4f15-9e01-f68b416599ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "gnn_model.eval()\n",
    "with torch.no_grad():\n",
    "    out = gnn_model(data.x, full_edge_index)\n",
    "    preds = out.argmax(dim=1)\n",
    "    labels = data.y\n",
    "    mask = data.test_mask\n",
    "    test_preds = preds[mask].cpu().numpy()\n",
    "    test_labels = labels[mask].cpu().numpy()\n",
    "\n",
    "    accuracy = accuracy_score(test_labels, test_preds)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(test_labels, test_preds, average='macro')\n",
    "\n",
    "print(f\"GNN accuracy: {accuracy:.4f}, GNN precision: {precision:.4f}, GNN recall: {recall:.4f}, GNN F1 score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a50e018-d55d-4546-b713-7f098fd43165",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# GAE training loss history\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(GAE_loss_history, label='GAE training loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('GAE training loss history')\n",
    "plt.grid(True)  # Assuming you want to always display the grid\n",
    "plt.legend()\n",
    "\n",
    "# GNN training loss history\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(GNN_loss_history, label='GNN training loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('GNN training loss history')\n",
    "plt.grid(True)  # Assuming you want to always display the grid\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
